{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aca7653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit_learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit_learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit_learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit_learn) (3.5.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit_learn gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe66bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape: (9999, 146)\n",
      "Train Labels Shape: (49999, 34)\n",
      "   id   x1   x2                                            x3  \\\n",
      "0   1   NO   NO  dqOiM6yBYgnVSezBRiQXs9bvOFnRqrtIoXRIElxD7g8=   \n",
      "1   2  NaN  NaN                                           NaN   \n",
      "2   3   NO   NO  ib4VpsEsqJHzDiyL0dZLQ+xQzDPrkxE+9T3mx5fv2wI=   \n",
      "3   4  YES   NO  BfrqME7vdLw3suQp6YAT16W2piNUmpKhMzuDrVrFQ4w=   \n",
      "4   5   NO   NO  RTjsrrR8DTlJyaIP9Q3Z8s0zseqlVQTrlSe97GCWfbk=   \n",
      "\n",
      "                                             x4        x5        x6        x7  \\\n",
      "0  GNjrXXA3SxbgD0dTRblAPO9jFJ7AIaZnu/f48g5XSUk=  0.576561  0.073139  0.481394   \n",
      "1                                           NaN  0.000000  0.000000  0.000000   \n",
      "2  X6dDAI/DZOWvu0Dg6gCgRoNr2vTUz/mc4SdHTNUPS38=  1.341803  0.051422  0.935572   \n",
      "3  YGCdISifn4fLao/ASKdZFhGIq23oqzfSbUVb6px1pig=  0.653912  0.041471  0.940787   \n",
      "4  3yK2OPj1uYDsoMgsxsjY1FxXkOllD8Xfh20VYGqT+nU=  1.415919  0.000000  1.000000   \n",
      "\n",
      "         x8        x9  ... x136   x137  x138  x139 x140  x141  x142  x143  \\\n",
      "0  0.115697  0.472474  ...  0.0  0.810  3306  4676  YES    NO   YES     2   \n",
      "1  0.000000  0.000000  ...  0.0  0.510  4678  3306  YES    NO   YES     4   \n",
      "2  0.041440  0.501710  ...  0.0  0.850  4678  3306   NO    NO    NO     1   \n",
      "3  0.090851  0.556564  ...  0.0  0.945  3306  4678   NO    NO   YES     3   \n",
      "4  0.000000  0.375297  ...  0.0  1.000  1263   892   NO    NO    NO     1   \n",
      "\n",
      "       x144      x145  \n",
      "0  0.375535  0.464610  \n",
      "1  0.741682  0.593630  \n",
      "2  0.776467  0.493159  \n",
      "3  0.168234  0.546582  \n",
      "4  0.246637  0.361045  \n",
      "\n",
      "[5 rows x 146 columns]\n",
      "   id  y1  y2  y3  y4  y5  y6  y7  y8  y9  ...  y24  y25  y26  y27  y28  y29  \\\n",
      "0   1   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "1   2   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "2   3   0   0   1   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "3   4   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "4   5   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "\n",
      "   y30  y31  y32  y33  \n",
      "0    0    0    0    1  \n",
      "1    0    0    1    0  \n",
      "2    0    0    0    0  \n",
      "3    0    0    0    1  \n",
      "4    0    0    0    1  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "#1_Data_Loading_n_Preprocessing:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_features = pd.read_csv('train.csv')\n",
    "train_labels = pd.read_csv('trainLabels.csv')\n",
    "\n",
    "# Inspect the data\n",
    "print(\"Train Features Shape:\", train_features.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(train_features.head())\n",
    "print(train_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e728518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "x1      1426\n",
      "x2      1426\n",
      "x3      1426\n",
      "x4      1426\n",
      "        ... \n",
      "x141       0\n",
      "x142       0\n",
      "x143       0\n",
      "x144       0\n",
      "x145       0\n",
      "Length: 146, dtype: int64\n",
      "id     0\n",
      "y1     0\n",
      "y2     0\n",
      "y3     0\n",
      "y4     0\n",
      "y5     0\n",
      "y6     0\n",
      "y7     0\n",
      "y8     0\n",
      "y9     0\n",
      "y10    0\n",
      "y11    0\n",
      "y12    0\n",
      "y13    0\n",
      "y14    0\n",
      "y15    0\n",
      "y16    0\n",
      "y17    0\n",
      "y18    0\n",
      "y19    0\n",
      "y20    0\n",
      "y21    0\n",
      "y22    0\n",
      "y23    0\n",
      "y24    0\n",
      "y25    0\n",
      "y26    0\n",
      "y27    0\n",
      "y28    0\n",
      "y29    0\n",
      "y30    0\n",
      "y31    0\n",
      "y32    0\n",
      "y33    0\n",
      "dtype: int64\n",
      "                id           x5           x6           x7           x8  \\\n",
      "count  9999.000000  9999.000000  9999.000000  9999.000000  9999.000000   \n",
      "mean   5000.000000     0.964933     0.053623     0.791668     0.172705   \n",
      "std    2886.607005     0.524688     0.128503     0.353194     0.329020   \n",
      "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%    2500.500000     0.642796     0.000000     0.831299     0.000000   \n",
      "50%    5000.000000     1.285541     0.000000     0.960637     0.000000   \n",
      "75%    7499.500000     1.414798     0.058076     1.000000     0.151543   \n",
      "max    9999.000000     1.474916     0.992745     1.000000     1.393289   \n",
      "\n",
      "                x9          x15          x16          x17          x18  ...  \\\n",
      "count  9999.000000  9999.000000  9999.000000  9999.000000  9999.000000  ...   \n",
      "mean      0.448091     6.056806     0.418593     4.483448     8.073907  ...   \n",
      "std       0.300549     8.756490     0.294579     4.388639     7.032278  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.199617     1.000000     0.165599     2.000000     3.000000  ...   \n",
      "50%       0.439504     3.000000     0.395740     4.000000     7.000000  ...   \n",
      "75%       0.682880     7.000000     0.683908     6.000000    11.000000  ...   \n",
      "max       1.098257    88.000000     1.180828   132.000000   118.000000  ...   \n",
      "\n",
      "              x133         x134         x135         x136         x137  \\\n",
      "count  9999.000000  9999.000000  9999.000000  9999.000000  9999.000000   \n",
      "mean      9.291529     8.800880     0.933771     0.056523     0.924781   \n",
      "std       7.576648     6.584598     0.069921     1.520931     0.118496   \n",
      "min       1.000000     0.000000    -0.098334   -17.000000     0.000000   \n",
      "25%       4.000000     4.000000     0.916144     0.000000     0.880000   \n",
      "50%       7.000000     7.000000     0.949552     0.000000     1.000000   \n",
      "75%      13.000000    12.000000     0.972222     0.000000     1.000000   \n",
      "max      84.000000   118.000000     0.999947    23.000000     1.000000   \n",
      "\n",
      "              x138         x139         x143         x144         x145  \n",
      "count  9999.000000  9999.000000  9999.000000  9999.000000  9999.000000  \n",
      "mean   2669.290629  2142.907091     3.667767     0.519482     0.505084  \n",
      "std    1588.220409  1386.559408    11.014722     0.270886     0.256323  \n",
      "min     892.000000   838.000000     0.000000     0.021635     0.001327  \n",
      "25%    1262.000000   892.000000     1.000000     0.267939     0.306031  \n",
      "50%    1263.000000   918.000000     2.000000     0.517937     0.484561  \n",
      "75%    4672.000000  3308.000000     5.000000     0.759242     0.707324  \n",
      "max    5217.000000  6622.000000   697.000000     1.238562     1.086371  \n",
      "\n",
      "[8 rows x 86 columns]\n",
      "                 id            y1            y2            y3            y4  \\\n",
      "count  49999.000000  49999.000000  49999.000000  49999.000000  49999.000000   \n",
      "mean   25000.000000      0.005620      0.000660      0.021060      0.013260   \n",
      "std    14433.612391      0.074757      0.025682      0.143587      0.114388   \n",
      "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    12500.500000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    25000.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    37499.500000      0.000000      0.000000      0.000000      0.000000   \n",
      "max    49999.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                 y5            y6            y7            y8            y9  \\\n",
      "count  49999.000000  49999.000000  49999.000000  49999.000000  49999.000000   \n",
      "mean       0.000180      0.074681      0.038001      0.000720      0.077502   \n",
      "std        0.013415      0.262879      0.191200      0.026824      0.267388   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "       ...           y24           y25           y26           y27  \\\n",
      "count  ...  49999.000000  49999.000000  49999.000000  49999.000000   \n",
      "mean   ...      0.017840      0.002720      0.010680      0.009500   \n",
      "std    ...      0.132372      0.052084      0.102793      0.097006   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                y28           y29           y30           y31           y32  \\\n",
      "count  49999.000000  49999.000000  49999.000000  49999.000000  49999.000000   \n",
      "mean       0.009700      0.031381      0.022900      0.028921      0.056161   \n",
      "std        0.098012      0.174346      0.149588      0.167585      0.230235   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                y33  \n",
      "count  49999.000000  \n",
      "mean       0.560351  \n",
      "std        0.496349  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "[8 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_features.isnull().sum())\n",
    "print(train_labels.isnull().sum())\n",
    "\n",
    "# Basic data statistics\n",
    "print(train_features.describe())\n",
    "print(train_labels.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23aa911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id      0\n",
      "x1      0\n",
      "x2      0\n",
      "x3      0\n",
      "x4      0\n",
      "       ..\n",
      "x141    0\n",
      "x142    0\n",
      "x143    0\n",
      "x144    0\n",
      "x145    0\n",
      "Length: 146, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/5hmfbqr17y12_gxw5ps7slkw0000gp/T/ipykernel_90261/2011777375.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_features[column].fillna(train_features[column].mean(), inplace=True)\n",
      "/var/folders/g0/5hmfbqr17y12_gxw5ps7slkw0000gp/T/ipykernel_90261/2011777375.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_features[column].fillna(train_features[column].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "# For simplicity, let's fill missing numerical values with the mean and categorical with the mode\n",
    "\n",
    "for column in train_features.columns:\n",
    "    if train_features[column].dtype == 'object':\n",
    "        train_features[column].fillna(train_features[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        train_features[column].fillna(train_features[column].mean(), inplace=True)\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(train_features.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a228a66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Features Shape: (9999, 34855)\n",
      "   id        x5        x6        x7        x8        x9  x15       x16  x17  \\\n",
      "0   1  0.576561  0.073139  0.481394  0.115697  0.472474   42  0.396065    3   \n",
      "1   2  0.000000  0.000000  0.000000  0.000000  0.000000    0  0.000000    0   \n",
      "2   3  1.341803  0.051422  0.935572  0.041440  0.501710    2  0.838475    3   \n",
      "3   4  0.653912  0.041471  0.940787  0.090851  0.556564   37  0.127405    8   \n",
      "4   5  1.415919  0.000000  1.000000  0.000000  0.375297    1  0.523543    4   \n",
      "\n",
      "   x18  ...  x129_NO  x129_YES  x130_NO  x130_YES  x140_NO  x140_YES  x141_NO  \\\n",
      "0    6  ...      1.0       0.0      1.0       0.0      0.0       1.0      1.0   \n",
      "1    0  ...      1.0       0.0      1.0       0.0      0.0       1.0      1.0   \n",
      "2    5  ...      1.0       0.0      1.0       0.0      1.0       0.0      1.0   \n",
      "3   15  ...      1.0       0.0      1.0       0.0      1.0       0.0      1.0   \n",
      "4   11  ...      1.0       0.0      1.0       0.0      1.0       0.0      1.0   \n",
      "\n",
      "   x141_YES  x142_NO  x142_YES  \n",
      "0       0.0      0.0       1.0  \n",
      "1       0.0      0.0       1.0  \n",
      "2       0.0      1.0       0.0  \n",
      "3       0.0      0.0       1.0  \n",
      "4       0.0      1.0       0.0  \n",
      "\n",
      "[5 rows x 34855 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = train_features.select_dtypes(include=['object']).columns\n",
    "numerical_features = train_features.select_dtypes(include=['number']).columns\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_categorical_features = pd.DataFrame(encoder.fit_transform(train_features[categorical_features]))\n",
    "\n",
    "# Fix the column names for the encoded features\n",
    "encoded_categorical_features.columns = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "processed_features = pd.concat([train_features[numerical_features].reset_index(drop=True), \n",
    "                                encoded_categorical_features.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"Processed Features Shape:\", processed_features.shape)\n",
    "print(processed_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97772989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape: (9999, 146)\n",
      "Train Labels Shape: (49999, 34)\n",
      "   id   x1   x2                                            x3  \\\n",
      "0   1   NO   NO  dqOiM6yBYgnVSezBRiQXs9bvOFnRqrtIoXRIElxD7g8=   \n",
      "1   2  NaN  NaN                                           NaN   \n",
      "2   3   NO   NO  ib4VpsEsqJHzDiyL0dZLQ+xQzDPrkxE+9T3mx5fv2wI=   \n",
      "3   4  YES   NO  BfrqME7vdLw3suQp6YAT16W2piNUmpKhMzuDrVrFQ4w=   \n",
      "4   5   NO   NO  RTjsrrR8DTlJyaIP9Q3Z8s0zseqlVQTrlSe97GCWfbk=   \n",
      "\n",
      "                                             x4        x5        x6        x7  \\\n",
      "0  GNjrXXA3SxbgD0dTRblAPO9jFJ7AIaZnu/f48g5XSUk=  0.576561  0.073139  0.481394   \n",
      "1                                           NaN  0.000000  0.000000  0.000000   \n",
      "2  X6dDAI/DZOWvu0Dg6gCgRoNr2vTUz/mc4SdHTNUPS38=  1.341803  0.051422  0.935572   \n",
      "3  YGCdISifn4fLao/ASKdZFhGIq23oqzfSbUVb6px1pig=  0.653912  0.041471  0.940787   \n",
      "4  3yK2OPj1uYDsoMgsxsjY1FxXkOllD8Xfh20VYGqT+nU=  1.415919  0.000000  1.000000   \n",
      "\n",
      "         x8        x9  ... x136   x137  x138  x139 x140  x141  x142  x143  \\\n",
      "0  0.115697  0.472474  ...  0.0  0.810  3306  4676  YES    NO   YES     2   \n",
      "1  0.000000  0.000000  ...  0.0  0.510  4678  3306  YES    NO   YES     4   \n",
      "2  0.041440  0.501710  ...  0.0  0.850  4678  3306   NO    NO    NO     1   \n",
      "3  0.090851  0.556564  ...  0.0  0.945  3306  4678   NO    NO   YES     3   \n",
      "4  0.000000  0.375297  ...  0.0  1.000  1263   892   NO    NO    NO     1   \n",
      "\n",
      "       x144      x145  \n",
      "0  0.375535  0.464610  \n",
      "1  0.741682  0.593630  \n",
      "2  0.776467  0.493159  \n",
      "3  0.168234  0.546582  \n",
      "4  0.246637  0.361045  \n",
      "\n",
      "[5 rows x 146 columns]\n",
      "   id  y1  y2  y3  y4  y5  y6  y7  y8  y9  ...  y24  y25  y26  y27  y28  y29  \\\n",
      "0   1   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "1   2   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "2   3   0   0   1   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "3   4   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "4   5   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
      "\n",
      "   y30  y31  y32  y33  \n",
      "0    0    0    0    1  \n",
      "1    0    0    1    0  \n",
      "2    0    0    0    0  \n",
      "3    0    0    0    1  \n",
      "4    0    0    0    1  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "id         0\n",
      "x1      1426\n",
      "x2      1426\n",
      "x3      1426\n",
      "x4      1426\n",
      "        ... \n",
      "x141       0\n",
      "x142       0\n",
      "x143       0\n",
      "x144       0\n",
      "x145       0\n",
      "Length: 146, dtype: int64\n",
      "id     0\n",
      "y1     0\n",
      "y2     0\n",
      "y3     0\n",
      "y4     0\n",
      "y5     0\n",
      "y6     0\n",
      "y7     0\n",
      "y8     0\n",
      "y9     0\n",
      "y10    0\n",
      "y11    0\n",
      "y12    0\n",
      "y13    0\n",
      "y14    0\n",
      "y15    0\n",
      "y16    0\n",
      "y17    0\n",
      "y18    0\n",
      "y19    0\n",
      "y20    0\n",
      "y21    0\n",
      "y22    0\n",
      "y23    0\n",
      "y24    0\n",
      "y25    0\n",
      "y26    0\n",
      "y27    0\n",
      "y28    0\n",
      "y29    0\n",
      "y30    0\n",
      "y31    0\n",
      "y32    0\n",
      "y33    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/5hmfbqr17y12_gxw5ps7slkw0000gp/T/ipykernel_90261/1288792104.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_features[column].fillna(train_features[column].mean(), inplace=True)\n",
      "/var/folders/g0/5hmfbqr17y12_gxw5ps7slkw0000gp/T/ipykernel_90261/1288792104.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_features[column].fillna(train_features[column].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                               49995000\n",
      "x1      NONONOYESNONONONONONONOYESNOYESNONONONONONONON...\n",
      "x2      NONONONONONONONONONONOYESNONONONONONONONONONON...\n",
      "x3      dqOiM6yBYgnVSezBRiQXs9bvOFnRqrtIoXRIElxD7g8=MZ...\n",
      "x4      GNjrXXA3SxbgD0dTRblAPO9jFJ7AIaZnu/f48g5XSUk=hC...\n",
      "                              ...                        \n",
      "x141    NONONONONONONONONONONONONONONONONONONONONONONO...\n",
      "x142    YESYESNOYESNOYESYESNOYESYESNOYESYESYESNOYESNOY...\n",
      "x143                                                36674\n",
      "x144                                          5194.296623\n",
      "x145                                          5050.337816\n",
      "Length: 146, dtype: object\n",
      "Processed Features Shape: (9999, 34855)\n",
      "   id        x5        x6        x7        x8        x9  x15       x16  x17  \\\n",
      "0   1  0.576561  0.073139  0.481394  0.115697  0.472474   42  0.396065    3   \n",
      "1   2  0.000000  0.000000  0.000000  0.000000  0.000000    0  0.000000    0   \n",
      "2   3  1.341803  0.051422  0.935572  0.041440  0.501710    2  0.838475    3   \n",
      "3   4  0.653912  0.041471  0.940787  0.090851  0.556564   37  0.127405    8   \n",
      "4   5  1.415919  0.000000  1.000000  0.000000  0.375297    1  0.523543    4   \n",
      "\n",
      "   x18  ...  x129_NO  x129_YES  x130_NO  x130_YES  x140_NO  x140_YES  x141_NO  \\\n",
      "0    6  ...      1.0       0.0      1.0       0.0      0.0       1.0      1.0   \n",
      "1    0  ...      1.0       0.0      1.0       0.0      0.0       1.0      1.0   \n",
      "2    5  ...      1.0       0.0      1.0       0.0      1.0       0.0      1.0   \n",
      "3   15  ...      1.0       0.0      1.0       0.0      1.0       0.0      1.0   \n",
      "4   11  ...      1.0       0.0      1.0       0.0      1.0       0.0      1.0   \n",
      "\n",
      "   x141_YES  x142_NO  x142_YES  \n",
      "0       0.0      0.0       1.0  \n",
      "1       0.0      0.0       1.0  \n",
      "2       0.0      1.0       0.0  \n",
      "3       0.0      0.0       1.0  \n",
      "4       0.0      1.0       0.0  \n",
      "\n",
      "[5 rows x 34855 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the datasets\n",
    "train_features = pd.read_csv('train.csv')\n",
    "train_labels = pd.read_csv('trainLabels.csv')\n",
    "\n",
    "# Inspect the data\n",
    "print(\"Train Features Shape:\", train_features.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(train_features.head())\n",
    "print(train_labels.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(train_features.isnull().sum())\n",
    "print(train_labels.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "for column in train_features.columns:\n",
    "    if train_features[column].dtype == 'object':\n",
    "        train_features[column].fillna(train_features[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        train_features[column].fillna(train_features[column].mean(), inplace=True)\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(train_features.fillna(0).sum())\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = train_features.select_dtypes(include=['object']).columns\n",
    "numerical_features = train_features.select_dtypes(include=['number']).columns\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_categorical_features = pd.DataFrame(encoder.fit_transform(train_features[categorical_features]))\n",
    "\n",
    "# Fix the column names for the encoded features\n",
    "encoded_categorical_features.columns = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "processed_features = pd.concat([train_features[numerical_features].reset_index(drop=True), \n",
    "                                encoded_categorical_features.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"Processed Features Shape:\", processed_features.shape)\n",
    "print(processed_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41397f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   another  data  example  is  sample  text  this\n",
      "0        0     0        0   1       1     0     1\n",
      "1        1     0        1   1       0     0     1\n",
      "2        0     1        0   0       1     1     0\n"
     ]
    }
   ],
   "source": [
    "#2_Feature_Engineering(Bag_Of_Words):\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data for illustration (assuming we have a 'text' column in train_features)\n",
    "sample_texts = [\"this is a sample\", \"this is another example\", \"sample text data\"]\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the sample text data\n",
    "bow_features = count_vectorizer.fit_transform(sample_texts).toarray()\n",
    "\n",
    "# Convert to DataFrame\n",
    "bow_df = pd.DataFrame(bow_features, columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the BoW features\n",
    "print(bow_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc7100d-1983-47e5-b599-736cd92ccce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scipy==1.12) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851a6d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.006519  0.004237 -0.001714  0.002955  0.000257 -0.008938  0.007040   \n",
      "1 -0.011792  0.007407 -0.003109 -0.001603  0.005724 -0.010330  0.003259   \n",
      "2  0.004917 -0.004131 -0.001277  0.007402 -0.001716  0.005741  0.007864   \n",
      "\n",
      "         7         8         9   ...        40        41        42        43  \\\n",
      "0  0.008833 -0.002910 -0.002415  ... -0.003750 -0.001428 -0.007618 -0.003546   \n",
      "1  0.000938 -0.003392 -0.004002  ...  0.004225  0.002034  0.004890 -0.003521   \n",
      "2  0.012101 -0.009363  0.006768  ... -0.009407  0.003441 -0.004974 -0.003653   \n",
      "\n",
      "         44        45        46        47        48        49  \n",
      "0  0.008083  0.006100 -0.002383 -0.003210  0.002444  0.005933  \n",
      "1  0.010903  0.010580  0.002886 -0.005228  0.003749 -0.000603  \n",
      "2  0.000814  0.004598 -0.000587  0.003016 -0.005930  0.008471  \n",
      "\n",
      "[3 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "#Word_Embeddings:\n",
    "import numpy as np\n",
    "import gensim as gsm\n",
    "\n",
    "# Example text corpus (tokenized)\n",
    "corpus = [[\"this\", \"is\", \"a\", \"sample\"], [\"this\", \"is\", \"another\", \"example\"], [\"sample\", \"text\", \"data\"]]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "word2vec_model = gsm.models.Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get average word vectors for a text\n",
    "def get_average_word2vec(text, model, vector_size):\n",
    "    words = text.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Get Word2Vec features for each sample text\n",
    "word2vec_features = np.array([get_average_word2vec(text, word2vec_model, 50) for text in sample_texts])\n",
    "\n",
    "# Convert to DataFrame\n",
    "word2vec_df = pd.DataFrame(word2vec_features)\n",
    "\n",
    "# Display the Word2Vec features\n",
    "print(word2vec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "497bf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    another      data   example        is   sample      text      this\n",
      "0  0.000000  0.000000  0.000000  0.577350  0.57735  0.000000  0.577350\n",
      "1  0.562829  0.000000  0.562829  0.428046  0.00000  0.000000  0.428046\n",
      "2  0.000000  0.622766  0.000000  0.000000  0.47363  0.622766  0.000000\n"
     ]
    }
   ],
   "source": [
    "#TF_IDF_Vectorization:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the sample text data\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(sample_texts).toarray()\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_features, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the TF-IDF features\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23533d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id   x1   x2                                            x3  \\\n",
      "0        1   NO   NO  dqOiM6yBYgnVSezBRiQXs9bvOFnRqrtIoXRIElxD7g8=   \n",
      "1        2   NO   NO  MZZbXga8gvaCBqWpzrh2iKdOkcsz/bG/z4BVjUnqWT0=   \n",
      "2        3   NO   NO  ib4VpsEsqJHzDiyL0dZLQ+xQzDPrkxE+9T3mx5fv2wI=   \n",
      "3        4  YES   NO  BfrqME7vdLw3suQp6YAT16W2piNUmpKhMzuDrVrFQ4w=   \n",
      "4        5   NO   NO  RTjsrrR8DTlJyaIP9Q3Z8s0zseqlVQTrlSe97GCWfbk=   \n",
      "...    ...  ...  ...                                           ...   \n",
      "9994  9995   NO   NO  jComfqYTXYSeH3GvqcOhwPmldb+BCdVJDKKDNkdtw2w=   \n",
      "9995  9996   NO   NO  Pr5enXjzVzVjZziZxrDcgnyu6CLUftmEbnp6TctyJbU=   \n",
      "9996  9997  YES  YES  9Avs0tL1zvH7Xx41z2UqrXs11/4IWLmqRAodLt/SKjQ=   \n",
      "9997  9998   NO   NO  9zkXU3f6YnRPjsWi3lKSCLseIGrleg00tpRI4OplABw=   \n",
      "9998  9999  YES  YES  MZZbXga8gvaCBqWpzrh2iKdOkcsz/bG/z4BVjUnqWT0=   \n",
      "\n",
      "                                                x4        x5        x6  \\\n",
      "0     GNjrXXA3SxbgD0dTRblAPO9jFJ7AIaZnu/f48g5XSUk=  0.576561  0.073139   \n",
      "1     hCXwO/JldK5zcd9ejOD1FwmEgCf96eTdEVy7OtY2Y2g=  0.000000  0.000000   \n",
      "2     X6dDAI/DZOWvu0Dg6gCgRoNr2vTUz/mc4SdHTNUPS38=  1.341803  0.051422   \n",
      "3     YGCdISifn4fLao/ASKdZFhGIq23oqzfSbUVb6px1pig=  0.653912  0.041471   \n",
      "4     3yK2OPj1uYDsoMgsxsjY1FxXkOllD8Xfh20VYGqT+nU=  1.415919  0.000000   \n",
      "...                                            ...       ...       ...   \n",
      "9994  Kr2CC15nSwDjdpyAeVh4vOuIaHuC/Q7cL9BAK28JoG8=  1.207136  0.082855   \n",
      "9995  YvZUuCDjLu9VvkCdBWgARWQrvm+FSXgxp0zIrMjcLBc=  1.414798  0.000000   \n",
      "9996  WV5vAHFyqkeuyFB5KVNGFOBuwjkUGKYc8wh9QfpVzAA=  1.413677  0.000000   \n",
      "9997  gOZBAoajyr6i7GgON0N7q5+KE4JTwH3OUM0lZOWMuG8=  1.294118  0.000000   \n",
      "9998  YvZUuCDjLu9VvkCdBWgARWQrvm+FSXgxp0zIrMjcLBc=  0.660897  0.042735   \n",
      "\n",
      "            x7        x8        x9  ... x136   x137  x138  x139 x140  x141  \\\n",
      "0     0.481394  0.115697  0.472474  ...  0.0  0.810  3306  4676  YES    NO   \n",
      "1     0.000000  0.000000  0.000000  ...  0.0  0.510  4678  3306  YES    NO   \n",
      "2     0.935572  0.041440  0.501710  ...  0.0  0.850  4678  3306   NO    NO   \n",
      "3     0.940787  0.090851  0.556564  ...  0.0  0.945  3306  4678   NO    NO   \n",
      "4     1.000000  0.000000  0.375297  ...  0.0  1.000  1263   892   NO    NO   \n",
      "...        ...       ...       ...  ...  ...    ...   ...   ...  ...   ...   \n",
      "9994  0.918960  0.313880  0.495189  ...  0.0  0.810  4677  3307  YES    NO   \n",
      "9995  1.000000  0.000000  0.357369  ...  0.0  1.000  1262   892  YES    NO   \n",
      "9996  1.000000  0.000000  0.668517  ...  0.0  1.000  1261   892  YES    NO   \n",
      "9997  1.000000  0.000000  0.570707  ...  1.0  1.000  1188   918   NO    NO   \n",
      "9998  0.946581  0.086966  0.510278  ...  0.0  0.880  3308  4680  YES    NO   \n",
      "\n",
      "      x142  x143      x144      x145  \n",
      "0      YES     2  0.375535  0.464610  \n",
      "1      YES     4  0.741682  0.593630  \n",
      "2       NO     1  0.776467  0.493159  \n",
      "3      YES     3  0.168234  0.546582  \n",
      "4       NO     1  0.246637  0.361045  \n",
      "...    ...   ...       ...       ...  \n",
      "9994   YES     1  0.502268  0.486637  \n",
      "9995   YES    15  0.890135  0.346276  \n",
      "9996   YES     5  0.726457  0.659001  \n",
      "9997    NO     3  0.450980  0.561448  \n",
      "9998   YES     0  0.604274  0.499395  \n",
      "\n",
      "[9999 rows x 146 columns]\n",
      "Combined Features Shape: (9999, 34921)\n",
      "   id        x5        x6        x7        x8        x9  x15       x16  x17  \\\n",
      "0   1  0.576561  0.073139  0.481394  0.115697  0.472474   42  0.396065    3   \n",
      "1   2  0.000000  0.000000  0.000000  0.000000  0.000000    0  0.000000    0   \n",
      "2   3  1.341803  0.051422  0.935572  0.041440  0.501710    2  0.838475    3   \n",
      "3   4  0.653912  0.041471  0.940787  0.090851  0.556564   37  0.127405    8   \n",
      "4   5  1.415919  0.000000  1.000000  0.000000  0.375297    1  0.523543    4   \n",
      "\n",
      "   x18  ...        40        41        42        43        44        45  \\\n",
      "0    6  ... -0.003750 -0.001428 -0.007618 -0.003546  0.008083  0.006100   \n",
      "1    0  ...  0.004225  0.002034  0.004890 -0.003521  0.010903  0.010580   \n",
      "2    5  ... -0.009407  0.003441 -0.004974 -0.003653  0.000814  0.004598   \n",
      "3   15  ...  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   11  ...  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         46        47        48        49  \n",
      "0 -0.002383 -0.003210  0.002444  0.005933  \n",
      "1  0.002886 -0.005228  0.003749 -0.000603  \n",
      "2 -0.000587  0.003016 -0.005930  0.008471  \n",
      "3  0.000000  0.000000  0.000000  0.000000  \n",
      "4  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[5 rows x 34921 columns]\n"
     ]
    }
   ],
   "source": [
    "#Combinig_All_Features:\n",
    "# Assuming 'train_features' has a 'text' column containing the raw text data\n",
    "print(train_features)\n",
    "train_features['text'] = pd.Series(sample_texts)  # This line is for illustration purposes\n",
    "\n",
    "# Generate BoW features for the actual text data df['Review'].values.astype('U')\n",
    "bow_features = count_vectorizer.fit_transform(train_features['text'].values.astype('U')).toarray()\n",
    "bow_df = pd.DataFrame(bow_features, columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Generate TF-IDF features for the actual text data\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(train_features['text'].values.astype('U')).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_features, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Generate Word2Vec features for the actual text data\n",
    "word2vec_features = np.array([get_average_word2vec(text, word2vec_model, 50) for text in train_features['text'].fillna(\"\")])\n",
    "word2vec_df = pd.DataFrame(word2vec_features)\n",
    "\n",
    "# Combine all features\n",
    "combined_features = pd.concat([processed_features.reset_index(drop=True), bow_df, tfidf_df, word2vec_df], axis=1)\n",
    "\n",
    "print(\"Combined Features Shape:\", combined_features.shape)\n",
    "print(combined_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed7e6ce1-d3bd-43b5-b1a7-f50ecd7e69ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m y_train\u001b[38;5;241m.\u001b[39mcolumns  \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mlogistic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Predict on the validation set\u001b[39;00m\n\u001b[1;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/multioutput.py:544\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m    519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \n\u001b[1;32m    521\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/multioutput.py:247\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a fit method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 247\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno_validation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     check_classification_targets(y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:635\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m--> 635\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_separately:\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;66;03m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;66;03m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;66;03m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;66;03m# :(\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1299\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1299\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1059\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1059\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:111\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(X\u001b[38;5;241m.\u001b[39mdtype, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex floating\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "#3 Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(combined_features, train_features, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "X_train.columns  = X_train.columns.astype(str)\n",
    "y_train.columns  = y_train.columns.astype(str)\n",
    "\n",
    "# Train the model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = logistic_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7837ba9-b33a-4200-acad-175e27467943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
